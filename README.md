# hyperparameter-tuning-dsc

This is one of the most important tools that you will be using in your career as a Data Scientist.<br>
Please, make sure that you devote enough time to understand the material of this code along and work through the code challenge.<br>
All the effort that you put into it now will pay off in time saved during your Mod3, Mod4 and Mod5 projects, not to mention your professional career once you graduate.

## Hyperparameter Tuning

[Code along](https://github.com/learn-co-students/hyperparameter-tuning-dsc/blob/master/hyperparameter_optimisation.ipynb)<br>
[Exit Ticket](https://docs.google.com/forms/d/e/1FAIpQLSfw-kapnEkKu414uDxF1KV3mRjNtuydSbsaMdACD0HNnrNMIA/viewform)<br>
[Daily Challenge](https://github.com/learn-co-students/forest-and-gridsearch-daily-challenge)

## Learning objectives

By then end of the session students should be able to:
* [ ] Select an appropriate range of values for each hyper-parameter to optimise
* [ ] Run GridSearchCV to find the best combination of hyper-parameter values from the ranges provided
* [ ] Update the ranges of values for the hyper-parameter that are not granular enough or show optima at the edge of a range
* [ ] Set seeds in stratified k-fold object to make multiple runs of GridSearchCV comparable
* [ ] Compare Train and Validation performance in the GridSearchCV runs
* [ ] Visualise the GridSearchCV performance grid
* [ ] Compare multiple models and select the one that solves the problem best
